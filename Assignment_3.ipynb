{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tejb96/ml-nonlinear-models/blob/main/Assignment_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "92778525",
      "metadata": {
        "id": "92778525"
      },
      "source": [
        "# Assignment 3: Non-Linear Models and Validation Metrics (37 total marks)\n",
        "### Due: October 24 at 11:59pm\n",
        "\n",
        "### Name: Tejpreet Bal"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce31b39a",
      "metadata": {
        "id": "ce31b39a"
      },
      "source": [
        "### In this assignment, you will need to write code that uses non-linear models to perform classification and regression tasks. You will also be asked to describe the process by which you came up with the code. More details can be found below. Please cite any websites or AI tools that you used to help you with this assignment."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf275ca7",
      "metadata": {
        "id": "cf275ca7"
      },
      "source": [
        "### Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b67a661",
      "metadata": {
        "id": "2b67a661"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ee2d2c3",
      "metadata": {
        "id": "5ee2d2c3"
      },
      "source": [
        "## Part 1: Regression (14.5 marks)\n",
        "\n",
        "For this section, we will be continuing with the concrete example from yellowbrick. You will need to compare these results to the results from the previous assignment. Please use the results from the solution if you were unable to complete Assignment 2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8219f163",
      "metadata": {
        "id": "8219f163"
      },
      "source": [
        "### Step 1: Data Input (0.5 marks)\n",
        "\n",
        "The data used for this task can be downloaded using the yellowbrick library:\n",
        "https://www.scikit-yb.org/en/latest/api/datasets/concrete.html\n",
        "\n",
        "Use the yellowbrick function `load_concrete()` to load the concrete dataset into the feature matrix `X` and target vector `y`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2af8bd32",
      "metadata": {
        "id": "2af8bd32"
      },
      "outputs": [],
      "source": [
        "# TO DO: Import concrete dataset from yellowbrick library\n",
        "from yellowbrick.datasets import load_concrete\n",
        "X, y = load_concrete()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "42fea4cc",
      "metadata": {
        "id": "42fea4cc"
      },
      "source": [
        "### Step 2: Data Processing (0 marks)\n",
        "\n",
        "Data processing was completed in the previous assignment. No need to repeat here."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2a245d00",
      "metadata": {
        "id": "2a245d00"
      },
      "source": [
        "### Step 3: Implement Machine Learning Model\n",
        "\n",
        "1. Import the Decision Tree, Random Forest and Gradient Boosting Machines regression models from sklearn\n",
        "2. Instantiate the three models with `max_depth = 5`. Are there any other parameters that you will need to set?\n",
        "3. Implement each machine learning model with `X` and `y`"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f994e31",
      "metadata": {
        "id": "3f994e31"
      },
      "source": [
        "### Step 4: Validate Model\n",
        "\n",
        "Calculate the average training and validation accuracy using mean squared error with cross-validation. To do this, you will need to set `scoring='neg_mean_squared_error'` in your `cross_validate` function and negate the results (multiply by -1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5fc3f7a8",
      "metadata": {
        "id": "5fc3f7a8"
      },
      "source": [
        "### Step 5: Visualize Results (4 marks)\n",
        "\n",
        "1. Create a pandas DataFrame `results` with columns: Training accuracy and Validation accuracy, and index: DT, RF and GB\n",
        "2. Add the accuracy results to the `results` DataFrame\n",
        "3. Print `results`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fdc93a78",
      "metadata": {
        "id": "fdc93a78",
        "outputId": "0134a088-943d-49c8-f6a4-8b8cb9a1c4d2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>training_score</th>\n",
              "      <th>validation_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>DecisionTreeRegressor(max_depth=5, random_state=0)</th>\n",
              "      <td>47.918561</td>\n",
              "      <td>163.087775</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RandomForestRegressor(max_depth=5, max_features='log2', n_estimators=50,\\n                      random_state=0)</th>\n",
              "      <td>37.486629</td>\n",
              "      <td>133.418746</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GradientBoostingRegressor(learning_rate=0.01, max_depth=5, n_estimators=50,\\n                          random_state=0)</th>\n",
              "      <td>126.704953</td>\n",
              "      <td>195.065275</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    training_score  \\\n",
              "DecisionTreeRegressor(max_depth=5, random_state=0)       47.918561   \n",
              "RandomForestRegressor(max_depth=5, max_features...       37.486629   \n",
              "GradientBoostingRegressor(learning_rate=0.01, m...      126.704953   \n",
              "\n",
              "                                                    validation_score  \n",
              "DecisionTreeRegressor(max_depth=5, random_state=0)        163.087775  \n",
              "RandomForestRegressor(max_depth=5, max_features...        133.418746  \n",
              "GradientBoostingRegressor(learning_rate=0.01, m...        195.065275  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# TO DO: ADD YOUR CODE HERE FOR STEPS 3-5\n",
        "# Note: for any random state parameters, you can use random_state = 0\n",
        "# HINT: USING A LOOP TO STORE THE DATA IN YOUR RESULTS DATAFRAME WILL BE MORE EFFICIENT\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.model_selection import cross_validate\n",
        "\n",
        "DT = DecisionTreeRegressor(max_depth=5, random_state=0)\n",
        "DT.fit(X, y)\n",
        "\n",
        "RF = RandomForestRegressor(max_depth=5,max_features='log2',n_estimators=50,random_state=0)\n",
        "RF.fit(X, y)\n",
        "\n",
        "GB = GradientBoostingRegressor(max_depth=5,n_estimators=50,learning_rate=0.01,random_state=0)\n",
        "GB.fit(X, y)\n",
        "\n",
        "result={'training_score':{},'validation_score':{}}\n",
        "datasets=[ (X, y, DT),(X, y, RF), (X, y, GB)]\n",
        "\n",
        "for X_data, y_data, model in datasets:\n",
        "    scores = cross_validate(model, X_data, y_data, cv=5,\n",
        "                        scoring='neg_mean_squared_error',\n",
        "                       return_train_score=True)\n",
        "    train_score=-scores['train_score'].mean()\n",
        "    test_score=-scores['test_score'].mean()\n",
        "    result['training_score'][str(model)]=train_score\n",
        "    result['validation_score'][str(model)]=test_score\n",
        "\n",
        "results=pd.DataFrame(data=result)\n",
        "results.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31715a9d",
      "metadata": {
        "id": "31715a9d"
      },
      "source": [
        "Repeat the step above to print the R2 score instead of the mean-squared error. For this case, you can use `scoring='r2'`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83539f47",
      "metadata": {
        "id": "83539f47",
        "outputId": "44db35ed-5448-4754-df88-d27125869654"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>training_score</th>\n",
              "      <th>validation_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>DecisionTreeRegressor(max_depth=5, random_state=0)</th>\n",
              "      <td>0.822887</td>\n",
              "      <td>0.176210</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RandomForestRegressor(max_depth=5, max_features='log2', n_estimators=50,\\n                      random_state=0)</th>\n",
              "      <td>0.861670</td>\n",
              "      <td>0.316878</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GradientBoostingRegressor(learning_rate=0.01, max_depth=5, n_estimators=50,\\n                          random_state=0)</th>\n",
              "      <td>0.539213</td>\n",
              "      <td>0.136018</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    training_score  \\\n",
              "DecisionTreeRegressor(max_depth=5, random_state=0)        0.822887   \n",
              "RandomForestRegressor(max_depth=5, max_features...        0.861670   \n",
              "GradientBoostingRegressor(learning_rate=0.01, m...        0.539213   \n",
              "\n",
              "                                                    validation_score  \n",
              "DecisionTreeRegressor(max_depth=5, random_state=0)          0.176210  \n",
              "RandomForestRegressor(max_depth=5, max_features...          0.316878  \n",
              "GradientBoostingRegressor(learning_rate=0.01, m...          0.136018  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# TO DO: ADD YOUR CODE HERE\n",
        "result={'training_score':{},'validation_score':{}}\n",
        "datasets=[ (X, y, DT),(X, y, RF), (X, y, GB)]\n",
        "\n",
        "for X_data, y_data, model in datasets:\n",
        "    scores = cross_validate(model, X_data, y_data, cv=5,\n",
        "                        scoring='r2',\n",
        "                       return_train_score=True)\n",
        "    train_score=scores['train_score'].mean()\n",
        "    test_score=scores['test_score'].mean()\n",
        "    result['training_score'][str(model)]=train_score\n",
        "    result['validation_score'][str(model)]=test_score\n",
        "\n",
        "results=pd.DataFrame(data=result)\n",
        "results.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5257a98",
      "metadata": {
        "id": "a5257a98"
      },
      "source": [
        "### Questions (6 marks)\n",
        "1. How do these results compare to the results using a linear model in the previous assignment? Use values.\n",
        "1. Out of the models you tested, which model would you select for this dataset and why?\n",
        "1. If you wanted to increase the accuracy of the tree-based models, what would you do? Provide two suggestions.\n",
        "\n",
        "*ANSWER HERE*"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "521237c2",
      "metadata": {
        "id": "521237c2"
      },
      "source": [
        "1. The mean squared error (MSE) for the training score for DT was the lowest at 47.918561, for RF it was 37.486629, and for GB it was approximately 126.704953. MSE for validation score was much greater at 163.087775, 133.418746, and 195.065275 for DT, RF, and GB respectively. For the linear model the MSE was 111, and 96 for training and validation. The difference between training and validation scores for the models in this assignment for both MSE and r2 seem to suggest that these models could be overfitting.  \n",
        "\n",
        "2. I would select the linear regression model from the last assignment since it produced much better results.\n",
        "\n",
        "3. The accuracy of the tree-based models can be improved by adjusting the parameters associated with the model to prevent overfitting. For example, for the DT model max_depth,max_leaf_nodes, or min_samples_leaf can be adjusted. For RF and GB models, max_depth, and n_estimators can be adjusted.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "37b238f4",
      "metadata": {
        "id": "37b238f4"
      },
      "source": [
        "### Process Description (4 marks)\n",
        "Please describe the process you used to create your code. Cite any websites or generative AI tools used. You can use the following questions as guidance:\n",
        "1. Where did you source your code?\n",
        "1. In what order did you complete the steps?\n",
        "1. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
        "1. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "93097bfe",
      "metadata": {
        "id": "93097bfe"
      },
      "source": [
        "*DESCRIBE YOUR PROCESS HERE*\n",
        "\n",
        "1. I used the example codes provided for decisontrees on D2L.\n",
        "2. I completed the steps in order.  \n",
        "3. I asked AI how to reduce overfitting for the decision tree models and it gave me a bunch of parameters that I could potentially adjust. I did end up modifying the code just to see if I can get better results but wasn't able to.\n",
        "4. The instructions provided in the steps were helpful. For example in step 4, it specified to use the cross_val_score function with score=neg_mean_squared_error."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f7c6de86",
      "metadata": {
        "id": "f7c6de86"
      },
      "source": [
        "## Part 2: Classification (17.5 marks)\n",
        "\n",
        "You have been asked to develop code that can help the user classify different wine samples. Following the machine learning workflow described in class, write the relevant code in each of the steps below:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f9d33a8",
      "metadata": {
        "id": "5f9d33a8"
      },
      "source": [
        "### Step 1: Data Input (2 marks)\n",
        "\n",
        "The data used for this task can be downloaded from UCI: https://archive.ics.uci.edu/dataset/109/wine\n",
        "\n",
        "Use the pandas library to load the dataset. You must define the column headers if they are not included in the dataset\n",
        "\n",
        "You will need to split the dataset into feature matrix `X` and target vector `y`. Which column represents the target vector?\n",
        "\n",
        "Print the size and type of `X` and `y`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33583c67",
      "metadata": {
        "id": "33583c67",
        "outputId": "1f26ecaf-7a2e-43bb-824d-6ffe6eeee46f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X size = 2314 y size=  178 X types:  <class 'pandas.core.frame.DataFrame'> y types:  <class 'pandas.core.series.Series'> int64\n"
          ]
        }
      ],
      "source": [
        "# TO DO: Import wine dataset\n",
        "from ucimlrepo import fetch_ucirepo\n",
        "\n",
        "# fetch dataset\n",
        "wine = fetch_ucirepo(id=109)\n",
        "\n",
        "# data (as pandas dataframes)\n",
        "X = wine.data.features\n",
        "y = wine.data.targets\n",
        "y = y['class']\n",
        "# # metadata\n",
        "# print(wine.metadata)\n",
        "\n",
        "# # variable information\n",
        "# print(wine.variables)\n",
        "\n",
        "print(\"X size =\",X.size, \"y size= \", y.size, \"X types: \", type(X), \"y types: \", type(y),y.dtypes)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "156db208",
      "metadata": {
        "id": "156db208"
      },
      "source": [
        "### Step 2: Data Processing (1.5 marks)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a28af110",
      "metadata": {
        "id": "a28af110"
      },
      "source": [
        "Print the first five rows of the dataset to inspect:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea266921",
      "metadata": {
        "id": "ea266921",
        "outputId": "6aeb5707-efae-459d-e731-10d4dff23791"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Alcohol</th>\n",
              "      <th>Malicacid</th>\n",
              "      <th>Ash</th>\n",
              "      <th>Alcalinity_of_ash</th>\n",
              "      <th>Magnesium</th>\n",
              "      <th>Total_phenols</th>\n",
              "      <th>Flavanoids</th>\n",
              "      <th>Nonflavanoid_phenols</th>\n",
              "      <th>Proanthocyanins</th>\n",
              "      <th>Color_intensity</th>\n",
              "      <th>Hue</th>\n",
              "      <th>0D280_0D315_of_diluted_wines</th>\n",
              "      <th>Proline</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>14.23</td>\n",
              "      <td>1.71</td>\n",
              "      <td>2.43</td>\n",
              "      <td>15.6</td>\n",
              "      <td>127</td>\n",
              "      <td>2.80</td>\n",
              "      <td>3.06</td>\n",
              "      <td>0.28</td>\n",
              "      <td>2.29</td>\n",
              "      <td>5.64</td>\n",
              "      <td>1.04</td>\n",
              "      <td>3.92</td>\n",
              "      <td>1065</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>13.20</td>\n",
              "      <td>1.78</td>\n",
              "      <td>2.14</td>\n",
              "      <td>11.2</td>\n",
              "      <td>100</td>\n",
              "      <td>2.65</td>\n",
              "      <td>2.76</td>\n",
              "      <td>0.26</td>\n",
              "      <td>1.28</td>\n",
              "      <td>4.38</td>\n",
              "      <td>1.05</td>\n",
              "      <td>3.40</td>\n",
              "      <td>1050</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>13.16</td>\n",
              "      <td>2.36</td>\n",
              "      <td>2.67</td>\n",
              "      <td>18.6</td>\n",
              "      <td>101</td>\n",
              "      <td>2.80</td>\n",
              "      <td>3.24</td>\n",
              "      <td>0.30</td>\n",
              "      <td>2.81</td>\n",
              "      <td>5.68</td>\n",
              "      <td>1.03</td>\n",
              "      <td>3.17</td>\n",
              "      <td>1185</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>14.37</td>\n",
              "      <td>1.95</td>\n",
              "      <td>2.50</td>\n",
              "      <td>16.8</td>\n",
              "      <td>113</td>\n",
              "      <td>3.85</td>\n",
              "      <td>3.49</td>\n",
              "      <td>0.24</td>\n",
              "      <td>2.18</td>\n",
              "      <td>7.80</td>\n",
              "      <td>0.86</td>\n",
              "      <td>3.45</td>\n",
              "      <td>1480</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>13.24</td>\n",
              "      <td>2.59</td>\n",
              "      <td>2.87</td>\n",
              "      <td>21.0</td>\n",
              "      <td>118</td>\n",
              "      <td>2.80</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0.39</td>\n",
              "      <td>1.82</td>\n",
              "      <td>4.32</td>\n",
              "      <td>1.04</td>\n",
              "      <td>2.93</td>\n",
              "      <td>735</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Alcohol  Malicacid   Ash  Alcalinity_of_ash  Magnesium  Total_phenols  \\\n",
              "0    14.23       1.71  2.43               15.6        127           2.80   \n",
              "1    13.20       1.78  2.14               11.2        100           2.65   \n",
              "2    13.16       2.36  2.67               18.6        101           2.80   \n",
              "3    14.37       1.95  2.50               16.8        113           3.85   \n",
              "4    13.24       2.59  2.87               21.0        118           2.80   \n",
              "\n",
              "   Flavanoids  Nonflavanoid_phenols  Proanthocyanins  Color_intensity   Hue  \\\n",
              "0        3.06                  0.28             2.29             5.64  1.04   \n",
              "1        2.76                  0.26             1.28             4.38  1.05   \n",
              "2        3.24                  0.30             2.81             5.68  1.03   \n",
              "3        3.49                  0.24             2.18             7.80  0.86   \n",
              "4        2.69                  0.39             1.82             4.32  1.04   \n",
              "\n",
              "   0D280_0D315_of_diluted_wines  Proline  \n",
              "0                          3.92     1065  \n",
              "1                          3.40     1050  \n",
              "2                          3.17     1185  \n",
              "3                          3.45     1480  \n",
              "4                          2.93      735  "
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# TO DO: ADD YOUR CODE HERE\n",
        "X.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "834fc8fe",
      "metadata": {
        "id": "834fc8fe"
      },
      "source": [
        "Check to see if there are any missing values in the dataset. If necessary, select an appropriate method to fill-in the missing values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97c6e9dc",
      "metadata": {
        "id": "97c6e9dc",
        "outputId": "31823f16-b526-428c-b031-612ab5d69aa0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Alcohol                         0\n",
            "Malicacid                       0\n",
            "Ash                             0\n",
            "Alcalinity_of_ash               0\n",
            "Magnesium                       0\n",
            "Total_phenols                   0\n",
            "Flavanoids                      0\n",
            "Nonflavanoid_phenols            0\n",
            "Proanthocyanins                 0\n",
            "Color_intensity                 0\n",
            "Hue                             0\n",
            "0D280_0D315_of_diluted_wines    0\n",
            "Proline                         0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# TO DO: ADD YOUR CODE HERE\n",
        "print(X.isnull().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "070956af",
      "metadata": {
        "id": "070956af"
      },
      "source": [
        "How many samples do we have of each type of wine?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b37a6fd9",
      "metadata": {
        "id": "b37a6fd9",
        "outputId": "e8ca9fc2-c9a8-47a0-b943-7447e430cfe5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "class\n",
              "2    71\n",
              "1    59\n",
              "3    48\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# TO DO: ADD YOUR CODE HERE\n",
        "y.value_counts()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "70e6c46f",
      "metadata": {
        "id": "70e6c46f"
      },
      "source": [
        "### Step 3: Implement Machine Learning Model\n",
        "\n",
        "1. Import `SVC` and `DecisionTreeClassifier` from sklearn\n",
        "2. Instantiate models as `SVC()` and `DecisionTreeClassifier(max_depth = 3)`\n",
        "3. Implement the machine learning model with `X` and `y`"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0870b0d2",
      "metadata": {
        "id": "0870b0d2"
      },
      "source": [
        "### Step 4: Validate Model\n",
        "\n",
        "Calculate the average training and validation accuracy using `cross_validate` for the two different models listed in Step 3. For this case, use `scoring='accuracy'`"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb0bbd83",
      "metadata": {
        "id": "bb0bbd83"
      },
      "source": [
        "### Step 5: Visualize Results (4 marks)\n",
        "\n",
        "#### Step 5.1: Compare Models\n",
        "1. Create a pandas DataFrame `results` with columns: Training accuracy and Validation accuracy\n",
        "2. Add the data size, training and validation accuracy for each dataset to the `results` DataFrame\n",
        "3. Print `results`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f109ff55",
      "metadata": {
        "id": "f109ff55"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be4b5c0a",
      "metadata": {
        "id": "be4b5c0a",
        "outputId": "5c026eca-880c-4242-da92-c841fdecc81e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>training_score</th>\n",
              "      <th>validation_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>DecisionTreeClassifier(max_depth=3, random_state=0)</th>\n",
              "      <td>0.994357</td>\n",
              "      <td>0.894017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SVC()</th>\n",
              "      <td>0.680427</td>\n",
              "      <td>0.676638</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    training_score  \\\n",
              "DecisionTreeClassifier(max_depth=3, random_stat...        0.994357   \n",
              "SVC()                                                     0.680427   \n",
              "\n",
              "                                                    validation_score  \n",
              "DecisionTreeClassifier(max_depth=3, random_stat...          0.894017  \n",
              "SVC()                                                       0.676638  "
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# TO DO: ADD YOUR CODE HERE FOR STEPS 3-5\n",
        "# Note: for any random state parameters, you can use random_state = 0\n",
        "# HINT: USING A LOOP TO STORE THE DATA IN YOUR RESULTS DATAFRAME WILL BE MORE EFFICIENT\n",
        "from sklearn.model_selection import train_test_split, cross_validate\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X,y,  random_state=0)\n",
        "\n",
        "tree = DecisionTreeClassifier(max_depth=3,random_state=0)\n",
        "tree.fit(X_train, y_train)\n",
        "\n",
        "svc = SVC()\n",
        "svc.fit(X_train, y_train)\n",
        "\n",
        "result={'training_score':{},'validation_score':{}}\n",
        "datasets=[ (X_train, y_train, tree),(X_train, y_train, svc)]\n",
        "\n",
        "for X_data, y_data, model in datasets:\n",
        "    scores = cross_validate(model, X_data, y_data, cv=5,\n",
        "                        scoring='accuracy',\n",
        "                       return_train_score=True)\n",
        "    train_score=scores['train_score'].mean()\n",
        "    test_score=scores['test_score'].mean()\n",
        "    result['training_score'][str(model)]=train_score\n",
        "    result['validation_score'][str(model)]=test_score\n",
        "\n",
        "results=pd.DataFrame(data=result)\n",
        "results.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2e17878",
      "metadata": {
        "id": "f2e17878"
      },
      "source": [
        "#### Step 5.2: Visualize Classification Errors\n",
        "Which method gave the highest accuracy? Use this method to print the confusion matrix and classification report:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "44b091a4",
      "metadata": {
        "id": "44b091a4"
      },
      "outputs": [],
      "source": [
        "# TO DO: Implement best model\n",
        "# DecisionTreeClassifier was the best model\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "y_pred_dt = tree.predict(X_test)\n",
        "cm = confusion_matrix(y_test, y_pred_dt)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09d21b59",
      "metadata": {
        "id": "09d21b59",
        "outputId": "392dc1a2-f6da-480e-e283-f22228876439"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x700 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# TO DO: Print confusion matrix using a heatmap\n",
        "fig, ax = plt.subplots(1, figsize=(10, 7))\n",
        "sns.heatmap(cm, annot=True, cmap='coolwarm')\n",
        "ax.set_xlabel('Predicted')\n",
        "ax.set_ylabel('Actual')\n",
        "ax.set_title('DecisionTreeClassifier')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ef95947",
      "metadata": {
        "id": "5ef95947",
        "outputId": "792ed0c4-af01-4c57-f64f-c389e2172e69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9333333333333333\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.88      0.93        16\n",
            "           2       0.91      0.95      0.93        21\n",
            "           3       0.89      1.00      0.94         8\n",
            "\n",
            "    accuracy                           0.93        45\n",
            "   macro avg       0.93      0.94      0.93        45\n",
            "weighted avg       0.94      0.93      0.93        45\n",
            "\n",
            "Confusion Matrix:\n",
            " [[14  2  0]\n",
            " [ 0 20  1]\n",
            " [ 0  0  8]]\n"
          ]
        }
      ],
      "source": [
        "# TO DO: Print classification report\n",
        "acc = accuracy_score(y_test, y_pred_dt)\n",
        "classification_repo = classification_report(y_test, y_pred_dt)\n",
        "cm = confusion_matrix(y_test, y_pred_dt)\n",
        "\n",
        "\n",
        "print(\"Accuracy:\", acc)\n",
        "print(\"Classification Report:\\n\", classification_repo)\n",
        "print(\"Confusion Matrix:\\n\", cm)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf319621",
      "metadata": {
        "id": "bf319621"
      },
      "source": [
        "### Questions (6 marks)\n",
        "1. How do the training and validation accuracy change depending on the method used? Explain with values.\n",
        "1. What are two reasons why the support vector machines model did not work as well as the tree-based model?\n",
        "1. How many samples were incorrectly classified in step 5.2?\n",
        "1. In this case, is maximizing precision or recall more important? Why?\n",
        "\n",
        "*YOUR ANSWERS HERE*"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f5693e7",
      "metadata": {
        "id": "4f5693e7"
      },
      "source": [
        "1. DTC had a training score of 0.99, and a validation score of 0.89. SVC had a scores of 0.68 and 0.68 for traning anc validation scores respectively. DTC did much better than the svc model.\n",
        "\n",
        "2. one of the reasons is because the default kernel is used. When the kernel is set to linear, validation score for SVC is  0.96, which is better than the DTC model.\n",
        "\n",
        "The second reason is that the data was not preprocessed, and the parameters were not tuned.\n",
        "\n",
        "3. Only 3 samples were incorrectly categorized using the DTC model.\n",
        "\n",
        "4. It depends on what the model is being used for. If the model is being used to classify wine samples into these 3 classes for quality purposes, maximizing precision would be better to decrease false positives. If the goal is to maximize profits, then recall should be improved to ensure all positives are captured.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "664ff8ae",
      "metadata": {
        "id": "664ff8ae"
      },
      "source": [
        "### Process Description (4 marks)\n",
        "Please describe the process you used to create your code. Cite any websites or generative AI tools used. You can use the following questions as guidance:\n",
        "1. Where did you source your code?\n",
        "1. In what order did you complete the steps?\n",
        "1. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
        "1. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0e837da",
      "metadata": {
        "id": "d0e837da"
      },
      "source": [
        "*DESCRIBE YOUR PROCESS HERE*"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b4a4e8a",
      "metadata": {
        "id": "0b4a4e8a"
      },
      "source": [
        "1. I used the example codes provided from lectures, and the lab solutions to complete this assignment.\n",
        "2. I completely the steps in order, and had to revisit a few steps to make corrects.\n",
        "3. I read in the slides that it is possible to change the kernel to improve accuracy, so I asked AI:\n",
        "\"is this linear from sklearn.svm import SVC\"\n",
        "It told me to use: svc_linear = SVC(kernel='linear'). I tried it and got a validation score of 0.96.\n",
        "4. I used the pip install method for the data as mentioned on the data website, and I kept getting an error for my target variable y which suggested I should use the .ravel() function. It did not work so I looked the error up, and realized it was because y was a pd.dataframe and not pd.series.\n",
        "The source used to fix error: https://stackoverflow.com/questions/34165731/a-column-vector-y-was-passed-when-a-1d-array-was-expected\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4cd7358d",
      "metadata": {
        "id": "4cd7358d"
      },
      "source": [
        "## Part 3: Observations/Interpretation (3 marks)\n",
        "\n",
        "Describe any pattern you see in the results. Relate your findings to what we discussed during lectures. Include data to justify your findings.\n",
        "\n",
        "\n",
        "*ADD YOUR FINDINGS HERE*"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9db8738b",
      "metadata": {
        "id": "9db8738b"
      },
      "source": [
        "For part 1, it says that DT, and GB dont seem to perform well when the parameters are not tuned properly in the slides, which seems to be the case. It also says that the RF model does not fit well to sparse data and the data contains many 0's.\n",
        "\n",
        "In the slides, it says that decision trees work well when you have features on a completely different scale, which for this data the features are. They seem to overfit easily which can be seen by slight adjustment of the max_depth to 5, which results in training score to increase to 1, and the validation score does not change. The doenside of the SVC discussed in the lecture slides is, that they require preprocessing of data and careful choice of the parameters. This can be seen from the substantial increase in the validation score from 0.68 to 0.96 just by changing the kernal from default to linear."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd97b6ac",
      "metadata": {
        "id": "cd97b6ac"
      },
      "source": [
        "## Part 4: Reflection (2 marks)\n",
        "Include a sentence or two about:\n",
        "- what you liked or disliked,\n",
        "- found interesting, confusing, challangeing, motivating\n",
        "while working on this assignment.\n",
        "\n",
        "\n",
        "*ADD YOUR THOUGHTS HERE*"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30f933b6",
      "metadata": {
        "id": "30f933b6"
      },
      "source": [
        "I disliked the results I got for part 1, the validation scores for the trees are very low. I found it interested how well the SVC model fit the data when kernel was set to linear."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fa21e53b",
      "metadata": {
        "id": "fa21e53b"
      },
      "source": [
        "## Part 5: Bonus Question (3 marks)\n",
        "\n",
        "Repeat Part 2 and compare the support vector machines model used to `LinearSVC(max_iter=5000)`. Does using `LinearSVC` improve the results? Why or why not?\n",
        "\n",
        "Is `LinearSVC` a good fit for this dataset? Why or why not?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30fea72e",
      "metadata": {
        "id": "30fea72e",
        "outputId": "c5bbe722-ffa3-4d8e-b415-9eba7e7b67ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Score: 0.9924704637630046\n",
            "Testing Score: 0.9772079772079773\n"
          ]
        }
      ],
      "source": [
        "# TO DO: ADD YOUR CODE HERE\n",
        "from sklearn.svm import LinearSVC\n",
        "lin_svc = LinearSVC(max_iter=5000,dual='auto')\n",
        "lin_svc.fit(X_train, y_train)\n",
        "scores = cross_validate(lin_svc, X_train, y_train, cv=5,\n",
        "                        scoring='accuracy',\n",
        "                       return_train_score=True)\n",
        "print(\"Training Score:\", scores['train_score'].mean())\n",
        "print(\"Testing Score:\", scores['test_score'].mean())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aabc68a4",
      "metadata": {
        "id": "aabc68a4"
      },
      "source": [
        "*ANSWER HERE*"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "427dc538",
      "metadata": {
        "id": "427dc538"
      },
      "source": [
        "LinearSVC is an execellent fit for this data since the test score is high, and the difference between test and training scores is not much."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}